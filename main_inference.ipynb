{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPWeACjg+xYkmboMPtfi+Ps"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RbEwcw_XqTJJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","dl_project_path ='MyDrive/ETH/DL_PROJECT/MAIN'\n","\n","env_path = f'/content/drive/{dl_project_path}'\n","\n","import sys\n","# Add the handout folder to python paths\n","if env_path not in sys.path:\n","    sys.path.append(env_path)"]},{"cell_type":"code","source":["# Installation of HuggingFace datasets\n","!pip install datasets\n","!pip install transformers\n","!pip install bitsandbytes\n","!pip install --upgrade peft\n","!pip install safetensors\n","!pip install evaluate\n","!pip install unsloth\n","!pip install openai"],"metadata":{"collapsed":true,"id":"q-k8EgdeqhqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from datasets import Dataset, load_dataset, load_from_disk\n","from unsloth import FastLanguageModel\n","from unsloth import is_bfloat16_supported\n","\n","\n","from openai import OpenAI\n","\n","device = 'cpu'\n","if torch.cuda.is_available():\n","    print('GPU available')\n","    device = 'cuda'\n","print(f'Device: {device}')"],"metadata":{"id":"RkyWUvAt2kiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the models\n","model_folders = [\"base_model\",\n","                 \"custom_model_constant\",\n","                 \"custom_model_samestart_adaptive\",\n","                 \"custom_model_samestart_adaptive_v2\",\n","                 \"custom_model_samestart_adaptive_v3\"]\n","\n","load_paths = { model_name: os.path.join(env_path, model_name) for model_name in model_folders}\n","\n","dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n","\n","models = {}\n","\n","for model_name, path in load_paths.items():\n","  if not os.path.exists(path):\n","    print(f\"Path {path} does not exist\")\n","  else:\n","    # select the last epoch\n","    start_epoch = max([int(f.split('_')[1]) for f in os.listdir(path) if f.startswith('epoch_')])\n","    print(f\"Loading model {model_name} from epoch {start_epoch}\")\n","    epoch_folder = os.path.join(path, f\"epoch_{start_epoch}\")\n","    model_path = f\"{epoch_folder}/lora_model\"\n","\n","    models[model_name], tokenizer = FastLanguageModel.from_pretrained(model_name=model_path,\n","                                                                      max_seq_length=2048,\n","                                                                      dtype=dtype,\n","                                                                      load_in_4bit=True)\n","\n","\n","states_path = os.path.join(epoch_folder, \"optimizer_scheduler.pt\") # epoch folder must be the one of the custom model\n","checkpoint = torch.load(states_path)\n","# Load training dictionary\n","training_dict = checkpoint[\"training_dictionary\"]\n","\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","bos_token = tokenizer.bos_token\n","eos_token = tokenizer.eos_token"],"metadata":{"id":"xViExtBzqobT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LOADING THE TEST DATASET"],"metadata":{"id":"97m9b2eJvJKa"}},{"cell_type":"code","source":["test_set_dir = os.path.join(env_path, 'dataset')\n","test_dataset = load_from_disk(os.path.join(test_set_dir ,'test_dataset'))"],"metadata":{"id":"CwAey13Cu-y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = test_dataset.select(range(100))"],"metadata":{"id":"4peS4Nne_CCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instruction dictionary\n","system_prompt = 'System Prompt: Answer the following user instruction based on the provided alignment attributes. '\n","system_instruction = bos_token + system_prompt + 'Alignment attributes: '\n","user_instruction = 'User instruction: '\n","instruct_dictionary = {'system': system_instruction, 'user': user_instruction}\n","\n","# Tokenize instruction dictionary\n","instruct_dictionary_tokenized = {}\n","instructions = [instruction for instruction in instruct_dictionary.keys()]\n","\n","for instruction in instructions:\n","    tokens = tokenizer(instruct_dictionary[instruction], padding = False, add_special_tokens=False)\n","    for key, value in tokens.items():\n","        instruct_dictionary_tokenized[f\"{instruction}_{key}\"] = torch.Tensor(value).long() # IDs and attention mask"],"metadata":{"id":"wjn22qNM9fvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class test_set_concatenator:\n","  \"\"\"\n","  Class to concatenate the prompt and response samples\n","  \"\"\"\n","\n","  def __init__(self, bos_token_id, eos_token_id, dict_instruct, attributes_to_use):\n","    self.bos_token_id = bos_token_id\n","    self.eos_token_id = eos_token_id\n","    self.dict_instruct = dict_instruct\n","    self.attributes_to_use = attributes_to_use\n","\n","  # mapping function\n","  def map(self, data):\n","\n","    # Get user and response instruction dictionary lengths\n","    data['prompt_ids'] = torch.cat([self.dict_instruct['user_input_ids'],\n","                                            data['prompt_input_ids'],\n","                                            torch.tensor(self.eos_token_id).unsqueeze(dim = 0)])\n","    data['prompt_att_mask'] = torch.cat([self.dict_instruct['user_attention_mask'],\n","                                                data['prompt_attention_mask'],\n","                                                torch.tensor(1).unsqueeze(dim = 0)])\n","\n","    data['length'] = data['prompt_ids'].shape[0]\n","\n","    return data\n","\n","\n","  def __call__(self, dataset):\n","    return dataset.map(self.map, batched=False)"],"metadata":{"id":"nvKuLnXm-Iaf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bos_token_id = tokenizer.bos_token_id\n","eos_token_id = tokenizer.eos_token_id\n","attributes_to_use = ['helpfulness', 'coherence', 'verbosity', 'correctness', 'complexity']\n","test_concatenator = test_set_concatenator(bos_token_id, eos_token_id, instruct_dictionary_tokenized, attributes_to_use)\n","test_dataset = test_concatenator(test_dataset)\n","\n","# select only prompt ids, prompt att mask and length columns\n","test_dataset = test_dataset.select_columns(['prompt_ids', 'prompt_att_mask', 'length'] + [f\"{attr}_input_ids\" for attr in attributes_to_use] + [f\"{attr}_attention_mask\" for attr in attributes_to_use])"],"metadata":{"id":"1aDDDsQw9CFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AttributeCollate:\n","  \"\"\"\n","  Class to collate the samples in the batch\n","  \"\"\"\n","\n","  def __init__(self, attributes, attribute_probs, num_attributes_per_batch,  dict_instruct, bos_id, eos_id, deterministic_attributes = None):\n","      self.attributes = attributes\n","      self.attribute_probs = attribute_probs\n","      self.num_attributes_per_batch = num_attributes_per_batch\n","      self.deterministic_attributes = deterministic_attributes # To be set when the proportions of attributes are precomputed withouth random extraction\n","      self.dict_instruct = dict_instruct\n","      self.bos_id = bos_id\n","      self.eos_id = eos_id\n","\n","      self.counter = 0 # used together with deterministic attributes\n","\n","\n","  def __call__(self, batch):\n","\n","      # batch is a list of samples, each a dict of tensors\n","      # Ensure attributes are selected without repetition\n","      if self.num_attributes_per_batch > len(self.attributes):\n","          raise ValueError(\"num_attributes_per_batch cannot exceed the number of unique attributes available.\")\n","\n","      # normalize attribute probs so that they sum up to one\n","      self.attribute_probs = self.attribute_probs / np.sum(self.attribute_probs)\n","\n","      if self.deterministic_attributes is not None:\n","        visible_attributes = [self.attributes[self.deterministic_attributes[self.counter]]]\n","        self.counter += 1\n","        if self.counter >= len(self.deterministic_attributes):\n","            self.counter = 0\n","      else:\n","        if self.num_attributes_per_batch == len(self.attributes):\n","            visible_attributes = self.attributes\n","        else:\n","          visible_attributes = np.random.choice(np.arange(0, len(self.attributes)), size=self.num_attributes_per_batch, replace=False, p=self.attribute_probs)\n","          visible_attributes = [self.attributes[i] for i in visible_attributes]\n","\n","      # bos + 'System Prompt: Answer the following user isntruction based on the provided alignment attributes. '\n","      system_instruct_ids = torch.stack([self.dict_instruct['system_input_ids']] * len(batch), dim=0)\n","      system_instruct_attmask = torch.full(system_instruct_ids.shape, 1)\n","\n","      # Actual attributes - 1 stack per attribute\n","      attr_id_list = []\n","      attr_attmask_list = []\n","      for attr in visible_attributes:\n","\n","          single_attr_ids = [sample[f\"{attr}_input_ids\"] for sample in batch]\n","          single_attr_attmask = [sample[f\"{attr}_attention_mask\"] for sample in batch]\n","\n","          single_attr_ids = torch.stack(single_attr_ids, dim=0)             # [batch_size, attr_seq_len]\n","          single_attr_attmask = torch.stack(single_attr_attmask, dim=0)     # [batch_size, attr_seq_len]\n","\n","          attr_id_list.append(single_attr_ids)\n","          attr_attmask_list.append(single_attr_attmask)\n","\n","      # Multiple attributes are concatenated along the sequence dimension (dim=1)\n","      if len(attr_id_list) > 0:\n","          attribute_ids = torch.cat(attr_id_list, dim=1)              # [batch_size, sum_of_all_attr_seq_len]\n","          attribute_attmask = torch.cat(attr_attmask_list, dim=1)     # [batch_size, sum_of_all_attr_seq_len]\n","      else:\n","          # If no attributes selected, just empty tensors\n","          attribute_ids = torch.empty(0, dtype=torch.long)\n","          attribute_attmask = torch.empty(0, dtype=torch.long)\n","\n","      # 'User Instruction: ' + prompt + eos\n","      # Get the maximum\n","      max_sequence_length = 0\n","      for sample in batch:\n","        if sample['length'] > max_sequence_length:\n","          max_sequence_length = sample['length']\n","\n","      # Init\n","      pad_prompt_ids = torch.full((len(batch), max_sequence_length), self.eos_id)\n","      pad_prompt_att_mask = torch.zeros((len(batch), max_sequence_length), dtype=torch.long)\n","\n","\n","      for i in range(len(batch)):\n","        pad_prompt_ids[i, :len(batch[i]['prompt_ids'])] = batch[i]['prompt_ids']\n","        pad_prompt_att_mask[i, :len(batch[i]['prompt_att_mask'])] = batch[i]['prompt_att_mask']\n","\n","      # Horizontal concatenation: # bos + 'System Prompt' + 'Alignment attributes: ' + actual attributes + 'User Instruction: ' + prompt + (eos + 'Response: ') + answer + eos\n","      input_ids = torch.cat([system_instruct_ids, attribute_ids, pad_prompt_ids], dim=1)\n","      attention_mask = torch.cat([system_instruct_attmask, attribute_attmask, pad_prompt_att_mask], dim=1)\n","\n","      # Inputs for model\n","      inputs = {\n","          'input_ids': input_ids,\n","          'attention_mask': attention_mask,\n","          'attributes': visible_attributes\n","      }\n","\n","      return inputs"],"metadata":{"id":"k0qf7y7BEZc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["initial_attributes = ['helpfulness', 'coherence', 'verbosity']\n","probs = [0.33, 0.33, 0.33]\n","num_attributes_per_batch = 1 # TODO: select the number of attributes to useS\n","\n","# In case of text generation with only ONE attribute at a time you can choose not to randomly pick the attributes\n","# For the total number of samples, generate a random vector so that there are equal proportions of all attributes\n","attributes_array = np.array([0] * 33 + [1] * 33 + [2] * 34)\n","# Perform a random permutation of the array --> all models at a time in text generation in order to have the same prompts (with same attributes) for evaluation\n","np.random.shuffle(attributes_array)\n","\n","collate_fn = AttributeCollate(initial_attributes, probs, num_attributes_per_batch, instruct_dictionary_tokenized, bos_token_id, eos_token_id, deterministic_attributes = attributes_array)\n","\n","# BATCH SIZE = 1 TO HAVE MEANINGFUL OUTPUTS\n","data_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"],"metadata":{"id":"Y2p9ehWgI-Ex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BATCH TEST\n","print(initial_attributes[attributes_array[0]])\n","\n","batch = next(iter(data_loader))\n","print(batch['input_ids'][0])\n","print(batch['attention_mask'][0])"],"metadata":{"id":"D8UfNmeL5-cC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["INFERENCE"],"metadata":{"id":"-DTUGJacJaH3"}},{"cell_type":"code","source":["# Inference loop\n","from tqdm.auto import tqdm\n","from torch.amp import autocast\n","\n","progress_bar = tqdm(range(len(data_loader)))\n","\n","prompts = []\n","responses = {model_name: [] for model_name in models.keys()}\n","\n","for model in models.values():\n","  FastLanguageModel.for_inference(model)\n","\n","for i, batch in enumerate(data_loader):\n","\n","  batch_attribute = batch.pop('attributes')\n","  #print(f\"Attributes: {batch_attribute}\")\n","  batch = {k: v.to(device) for k, v in batch.items()}\n","  full_prompt = tokenizer.decode(batch['input_ids'][0], skip_special_tokens=True)\n","  prompts.append(full_prompt[len(system_prompt):])\n","\n","  for key, model in models.items():\n","    # Text generation with the same prompt for all models\n","    outputs = model.generate(**batch, max_new_tokens=1024, use_cache = True)\n","    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    responses[key].append(full_response[len(full_prompt):])\n","\n","  progress_bar.update(1)\n"],"metadata":{"id":"cDllLzvbJZNR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GENERATION TESTS"],"metadata":{"id":"KLUB0mCO4Ap6"}},{"cell_type":"code","source":["sample_number = 89\n","responses[list(models.keys())[0]][sample_number]"],"metadata":{"id":"0zCNnl0V5Omf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(prompts[sample_number])"],"metadata":{"id":"mDfnGNvAJlpD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SAVING THE PROMTS AND ANSWERS"],"metadata":{"id":"qrLQR6vW4FlK"}},{"cell_type":"code","source":["import pickle\n","\n","inference_folder = 'inference_all_1_attr'\n","inference_path = os.path.join(env_path, inference_folder)\n","\n","if not os.path.exists(inference_path):\n","    os.makedirs(inference_path)\n","\n","# savig the prompts array into local dir\n","with open(os.path.join(inference_path, 'prompts.pkl'), 'wb') as f:\n","    pickle.dump(prompts, f)\n","\n","# saving the responses dictionary into a local dir\n","with open(os.path.join(inference_path, 'responses.pkl'), 'wb') as f:\n","    pickle.dump(responses, f)"],"metadata":{"id":"yyVfsubn4N8s"},"execution_count":null,"outputs":[]}]}