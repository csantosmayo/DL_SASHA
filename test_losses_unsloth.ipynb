{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMC57jeQlBtX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "dl_project_path ='MyDrive/Semester 3/DL/Code'\n",
        "\n",
        "env_path = f'/content/drive/{dl_project_path}'\n",
        "\n",
        "import sys\n",
        "# Add the handout folder to python paths\n",
        "if env_path not in sys.path:\n",
        "    sys.path.append(env_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vlLdlYkeipmt"
      },
      "outputs": [],
      "source": [
        "# Installation of HuggingFace datasets\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install --upgrade peft\n",
        "!pip install safetensors\n",
        "!pip install evaluate\n",
        "!pip install unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAxmxAt-LhyF"
      },
      "source": [
        "# Model, tokenizer and device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkIRS81yLgYd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "from transformers import LlamaForCausalLM, AutoTokenizer, get_scheduler, BitsAndBytesConfig\n",
        "from datasets import load_dataset, Dataset\n",
        "from bitsandbytes.optim import AdamW8bit, PagedAdamW8bit\n",
        "from peft import PeftModel, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "from utils import sample_selector, tokenization, dataset_concatenator, AttributeCollate, AlignmentTrainer, save_checkpoint, load_checkpoint, set_datasets\n",
        "\n",
        "# Device\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU available')\n",
        "    device = 'cuda'\n",
        "print(f'Device: {device}')\n",
        "\n",
        "# Seeds\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "\n",
        "# TODO\n",
        "training_path = \"custom_model_samestart_adaptive_v3/\"\n",
        "resume = True\n",
        "\n",
        "save_path = os.path.join(env_path, training_path)\n",
        "load_path = save_path\n",
        "\n",
        "model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "\n",
        "if resume:\n",
        "  # get last epoch number from the dir\n",
        "  if os.path.exists(load_path):\n",
        "    start_epoch = len(os.listdir(load_path)) - 3\n",
        "    epoch_folder = os.path.join(load_path, f\"epoch_{start_epoch-1}\")\n",
        "    model_name = f\"{epoch_folder}/lora_model\"\n",
        "    print(f\"Resuming from epoch {start_epoch}\")\n",
        "  else:\n",
        "    print(\"No checkpoints found\")\n",
        "    start_epoch = 0\n",
        "else:\n",
        "  start_epoch = 0\n",
        "  print(\"Starting from scratch\")\n",
        "\n",
        "# Load the tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=2048,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "if resume:\n",
        "  print(model.print_trainable_parameters())\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "bos_token = tokenizer.bos_token\n",
        "eos_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZzSc0TBMOiK"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncaXWt3p5Ixz"
      },
      "source": [
        "## Instruction dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TQSRstE5Ix0"
      },
      "outputs": [],
      "source": [
        "# Instruction dictionary\n",
        "system_instruction = bos_token + 'System Prompt: Answer the following user instruction based on the provided alignment attributes. Alignment attributes: '\n",
        "user_instruction = 'User instruction: '\n",
        "response_instruction = 'Response: '\n",
        "\n",
        "instruct_dictionary = {'system': system_instruction, 'user': user_instruction, 'response': response_instruction}\n",
        "\n",
        "# Tokenize instruction dictionary\n",
        "instruct_dictionary_tokenized = {}\n",
        "instructions = [instruction for instruction in instruct_dictionary.keys()]\n",
        "\n",
        "for instruction in instructions:\n",
        "\n",
        "    tokens = tokenizer(instruct_dictionary[instruction], padding = False, add_special_tokens=False)\n",
        "    instruct_dictionary_tokenized[f\"{instruction}_labels\"] = torch.Tensor([-100] * len(tokens[\"input_ids\"])).long() # Labels\n",
        "    for key, value in tokens.items():\n",
        "        instruct_dictionary_tokenized[f\"{instruction}_{key}\"] = torch.Tensor(value).long() # IDs and attention mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx2EFx-p5Ix2"
      },
      "source": [
        "## HelpSteer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRnrKuCl5Ix3"
      },
      "outputs": [],
      "source": [
        "dir = os.path.join(env_path, 'dataset')\n",
        "max_length = 1500\n",
        "attributes = ['helpfulness', 'coherence', 'verbosity', 'correctness', 'complexity']\n",
        "train_dataset, val_dataset, test_dataset = set_datasets(dir, tokenizer, instruct_dictionary_tokenized, max_length, attributes)\n",
        "\n",
        "print('Training dataset length: ', len(train_dataset))\n",
        "print('Length of val dataset:', len(val_dataset))\n",
        "print('Length of test dataset:', len(test_dataset))\n",
        "\n",
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Loss"
      ],
      "metadata": {
        "id": "Jx3pHLuaBATa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "from torch.amp import autocast, GradScaler"
      ],
      "metadata": {
        "id": "CvjDd9pKBy2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = {}"
      ],
      "metadata": {
        "id": "nBAaoefKBVUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All attributes"
      ],
      "metadata": {
        "id": "V9KiezjqBIGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All losses\n",
        "batch_size = 32\n",
        "bos_token_id = tokenizer.bos_token_id\n",
        "eos_token_id = tokenizer.eos_token_id\n",
        "initial_attributes = ['helpfulness', 'coherence', 'verbosity']\n",
        "initial_probs = [0.33, 0.33, 0.33]\n",
        "num_attributes_per_batch = 3\n",
        "\n",
        "collate_fn = AttributeCollate(attributes = initial_attributes,\n",
        "                                  attribute_probs = initial_probs,\n",
        "                                  num_attributes_per_batch = num_attributes_per_batch,\n",
        "                                  dict_instruct = instruct_dictionary_tokenized,\n",
        "                                  bos_id = bos_token_id,\n",
        "                                  eos_id = eos_token_id)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "zaXs_M1dAf_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ TEST LOOP------\n",
        "running_loss = 0\n",
        "model.eval()\n",
        "for batch in test_loader:\n",
        "  batch_attribute = batch.pop('attributes')\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "  with torch.no_grad(), autocast(device_type='cuda', dtype=dtype):\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "\n",
        "  running_loss += loss.item()\n",
        "\n",
        "test_loss['all'] = running_loss/len(test_loader)"
      ],
      "metadata": {
        "id": "42zRkY_UJ4as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helpfulness"
      ],
      "metadata": {
        "id": "5HotkWPmBsl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpfulness\n",
        "batch_size = 32\n",
        "bos_token_id = tokenizer.bos_token_id\n",
        "eos_token_id = tokenizer.eos_token_id\n",
        "initial_attributes = ['helpfulness', 'coherence', 'verbosity']\n",
        "initial_probs = [1, 0, 0]\n",
        "num_attributes_per_batch = 1\n",
        "\n",
        "collate_fn = AttributeCollate(attributes = initial_attributes,\n",
        "                                  attribute_probs = initial_probs,\n",
        "                                  num_attributes_per_batch = num_attributes_per_batch,\n",
        "                                  dict_instruct = instruct_dictionary_tokenized,\n",
        "                                  bos_id = bos_token_id,\n",
        "                                  eos_id = eos_token_id)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "0_e18YGGBr7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ TEST LOOP------\n",
        "running_loss = 0\n",
        "model.eval()\n",
        "for batch in test_loader:\n",
        "  batch_attribute = batch.pop('attributes')\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "  with torch.no_grad(), autocast(device_type='cuda', dtype=dtype):\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "\n",
        "  running_loss += loss.item()\n",
        "\n",
        "test_loss['helpfulness'] = running_loss/len(test_loader)"
      ],
      "metadata": {
        "id": "kkBDXCPSCBAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coherence"
      ],
      "metadata": {
        "id": "eZf2OksNCHVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coherence\n",
        "batch_size = 32\n",
        "bos_token_id = tokenizer.bos_token_id\n",
        "eos_token_id = tokenizer.eos_token_id\n",
        "initial_attributes = ['helpfulness', 'coherence', 'verbosity']\n",
        "initial_probs = [0, 1, 0]\n",
        "num_attributes_per_batch = 1\n",
        "\n",
        "collate_fn = AttributeCollate(attributes = initial_attributes,\n",
        "                                  attribute_probs = initial_probs,\n",
        "                                  num_attributes_per_batch = num_attributes_per_batch,\n",
        "                                  dict_instruct = instruct_dictionary_tokenized,\n",
        "                                  bos_id = bos_token_id,\n",
        "                                  eos_id = eos_token_id)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "i79CsnXaCI92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ TEST LOOP------\n",
        "running_loss = 0\n",
        "model.eval()\n",
        "for batch in test_loader:\n",
        "  batch_attribute = batch.pop('attributes')\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "  with torch.no_grad(), autocast(device_type='cuda', dtype=dtype):\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "\n",
        "  running_loss += loss.item()\n",
        "\n",
        "test_loss['coherence'] = running_loss/len(test_loader)"
      ],
      "metadata": {
        "id": "rOSvo7UACPTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verbosity"
      ],
      "metadata": {
        "id": "Tmv08HnfCQC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verbosity\n",
        "batch_size = 32\n",
        "bos_token_id = tokenizer.bos_token_id\n",
        "eos_token_id = tokenizer.eos_token_id\n",
        "initial_attributes = ['helpfulness', 'coherence', 'verbosity']\n",
        "initial_probs = [0, 0, 1]\n",
        "num_attributes_per_batch = 1\n",
        "\n",
        "collate_fn = AttributeCollate(attributes = initial_attributes,\n",
        "                                  attribute_probs = initial_probs,\n",
        "                                  num_attributes_per_batch = num_attributes_per_batch,\n",
        "                                  dict_instruct = instruct_dictionary_tokenized,\n",
        "                                  bos_id = bos_token_id,\n",
        "                                  eos_id = eos_token_id)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "XmQfONvgCQ4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ TEST LOOP------\n",
        "running_loss = 0\n",
        "model.eval()\n",
        "for batch in test_loader:\n",
        "  batch_attribute = batch.pop('attributes')\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "  with torch.no_grad(), autocast(device_type='cuda', dtype=dtype):\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "\n",
        "  running_loss += loss.item()\n",
        "\n",
        "test_loss['verbosity'] = running_loss/len(test_loader)"
      ],
      "metadata": {
        "id": "MIuPFMwDCYZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save losses"
      ],
      "metadata": {
        "id": "5Tm48Qe6D1sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"General loss: {test_loss['all']}\\n\"\n",
        "      f\"Helpfulness loss: {test_loss['helpfulness']}\\n\"\n",
        "      f\"Coherence loss: {test_loss['coherence']}\\n\"\n",
        "      f\"Verbosity loss: {test_loss['verbosity']}\")"
      ],
      "metadata": {
        "id": "wX7zfmi0E6dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(test_loss, os.path.join(epoch_folder, 'test_loss.pth'))"
      ],
      "metadata": {
        "id": "80kt2MFDD2sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDoiuAkVHQ2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}